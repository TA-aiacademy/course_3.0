{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9dd15852",
      "metadata": {
        "id": "9dd15852"
      },
      "source": [
        "# **GoogleNet**\n",
        "此份程式碼會介紹如何使用 tf.keras 的方式建構 GoogleNet 的模型架構，以及訓練的方式。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6fb147a",
      "metadata": {
        "id": "f6fb147a"
      },
      "source": [
        "<img src=\"https://hackmd.io/_uploads/rkWu7ywIp.png\" high=800/>\n",
        "- [source paper](https://arxiv.org/abs/1409.4842)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb094860",
      "metadata": {
        "id": "fb094860"
      },
      "source": [
        "## 匯入套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49929c0a",
      "metadata": {
        "id": "49929c0a"
      },
      "outputs": [],
      "source": [
        "# PyTorch 相關套件\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8affc19",
      "metadata": {
        "id": "d8affc19"
      },
      "source": [
        "## GoogleNet Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e282ed54",
      "metadata": {
        "id": "e282ed54"
      },
      "source": [
        "<img src=\"https://hackmd.io/_uploads/HJT6mkwI6.png\" width=1000/>\n",
        "\n",
        "- [source paper](https://arxiv.org/abs/1409.4842)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d2f039",
      "metadata": {},
      "outputs": [],
      "source": [
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.act(x)\n",
        "\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, filters_1x1, filters_3x3_reduce,\n",
        "                 filters_3x3, filters_5x5_reduce, filters_5x5,\n",
        "                 filters_pooling):\n",
        "        super().__init__()\n",
        "        # 1x1 Convolution\n",
        "        self.path1 = BasicConv2d(in_channels,\n",
        "                                 filters_1x1,\n",
        "                                 kernel_size=1,\n",
        "                                 padding='same')\n",
        "        self.path2 = nn.Sequential(\n",
        "            BasicConv2d(in_channels,\n",
        "                        filters_3x3_reduce,\n",
        "                        kernel_size=1,\n",
        "                        padding='same'),\n",
        "            BasicConv2d(filters_3x3_reduce,\n",
        "                        filters_3x3,\n",
        "                        kernel_size=3,\n",
        "                        padding='same'))\n",
        "        self.path3 = nn.Sequential(\n",
        "            BasicConv2d(in_channels,\n",
        "                        filters_5x5_reduce,\n",
        "                        kernel_size=1,\n",
        "                        padding='same'),\n",
        "            BasicConv2d(filters_5x5_reduce,\n",
        "                        filters_5x5,\n",
        "                        kernel_size=5,\n",
        "                        padding='same'))\n",
        "        self.path4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            BasicConv2d(in_channels,\n",
        "                        filters_pooling,\n",
        "                        kernel_size=1,\n",
        "                        padding='same'))\n",
        "\n",
        "    def forward(self, x):\n",
        "        p1 = self.path1(x)\n",
        "        p2 = self.path2(x)\n",
        "        p3 = self.path3(x)\n",
        "        p4 = self.path4(x)\n",
        "        return torch.cat((p1, p2, p3, p4), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e70d39",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AuxiliaryClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, num_classes, dropout=0.7):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.conv = BasicConv2d(in_channels,\n",
        "                                128,\n",
        "                                kernel_size=1,\n",
        "                                padding='same')\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=2048, out_features=1024), nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_features=1024, out_features=num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4a42c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n",
        "        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.aux1 = AuxiliaryClassifier(512, num_classes)\n",
        "        self.aux2 = AuxiliaryClassifier(528, num_classes)\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                        nn.Flatten(), nn.Dropout(0.4),\n",
        "                                        nn.Linear(1024, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "        aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        aux2 = self.aux2(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        x = self.classifier(x)\n",
        "        return x, aux1, aux2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affd1ba1",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GoogLeNet(10)\n",
        "\n",
        "inputs = torch.randn(1, 3, 224, 224)\n",
        "outputs = model(inputs)\n",
        "print(outputs[0].shape, outputs[1].shape, outputs[2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ffebab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# fake dataset for 224 images\n",
        "train_images = torch.randn(10, 3, 224, 224)\n",
        "train_labels = torch.randint(0, 10, (10, ))\n",
        "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=2,\n",
        "                                           shuffle=True)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for x, y in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    # mulpitle outputs and loss\n",
        "    loss1 = 1.0 * loss_fn(outputs[0], y)\n",
        "    loss2 = 0.3 * loss_fn(outputs[1], y)\n",
        "    loss3 = 0.3 * loss_fn(outputs[2], y)\n",
        "    loss = loss1 + loss2 + loss3\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12908910",
      "metadata": {
        "id": "12908910"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
