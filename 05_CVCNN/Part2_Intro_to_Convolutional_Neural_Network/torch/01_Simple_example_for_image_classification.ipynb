{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVehH4MNhbTP"
      },
      "source": [
        "# **CNN 入門**\n",
        "此份程式碼會介紹透過一個簡單的公開資料集，建置模型、訓練模型，並比較 DNN model 處理影像型資料的差異。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Q6g2Bfu6hB"
      },
      "source": [
        "## 匯入所需套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-K6b_vfX3iJ"
      },
      "outputs": [],
      "source": [
        "# import package\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBUtw-s24-wR"
      },
      "outputs": [],
      "source": [
        "# PyTorch 相關套件\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASS = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "BOQAkjdPhIwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awautmYIh4a2"
      },
      "source": [
        "## Cifar10 資料讀入及前處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aYh4Zbp4-wS"
      },
      "source": [
        "![image](https://hackmd.io/_uploads/B1VQW0L8T.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用torchvision的CIFAR10 dataset\n",
        "train_ds = torchvision.datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor(),\n",
        ")\n",
        "test_ds = torchvision.datasets.CIFAR10(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=T.ToTensor(),\n",
        ")\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(len(train_ds), 'train samples')\n",
        "print(len(test_ds), 'test samples')\n",
        "# train 中有 50000 筆訓練資料，以及 test 中有 10000 筆的測試資料"
      ],
      "metadata": {
        "id": "FL-_L_jTZd6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_ds[0]\n",
        "print(type(x), x.shape)\n",
        "print(type(y), y)\n",
        "# 第 1, 2 維度為影像大小 32*32、第 0 維度是 RGB 三原色，所以是 3"
      ],
      "metadata": {
        "id": "37mXygbcayvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all label from dataset\n",
        "y_train = [y for _, y in train_ds]\n",
        "y_test = [y for _, y in test_ds]"
      ],
      "metadata": {
        "id": "I-3j5v-tbaRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuE_e_dw4-wW"
      },
      "outputs": [],
      "source": [
        "uniques, counts = np.unique(y_train, return_counts=True)\n",
        "print(uniques, counts)\n",
        "\n",
        "plt.bar(uniques, counts)\n",
        "plt.xticks(uniques)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Kk71hT4-wX"
      },
      "outputs": [],
      "source": [
        "uniques, counts = np.unique(y_test, return_counts=True)\n",
        "print(uniques, counts)\n",
        "\n",
        "plt.bar(uniques, counts)\n",
        "plt.xticks(uniques)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hRQxZ5y4-wX"
      },
      "outputs": [],
      "source": [
        "img, label = train_ds[0]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.title(\"label: {}\".format(label), fontsize=15) # 第 0 筆圖像資料分類的位置\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pixel value 0~1\n",
        "plt.title('Distribution')\n",
        "plt.hist(img.flatten(), bins=100)\n",
        "plt.xlabel('pixel value')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JbWuH_tDb3td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqCH66zEiJ8m"
      },
      "source": [
        "## 模型定義"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3*32*32, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, NUM_CLASS),\n",
        ")\n",
        "print(dnn_model)"
      ],
      "metadata": {
        "id": "FmpFtQuEg1nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lku3uYxt4-wa"
      },
      "source": [
        "* ### CNN Model\n",
        "![image](https://hackmd.io/_uploads/r19BZCLUT.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = nn.Sequential(\n",
        "    # 第一層\n",
        "    # 建立卷積層，設定32個3*3的filters\n",
        "    # 設定ReLU為激活函數。\n",
        "    nn.Conv2d(3, 32, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    # 第二層 - 卷積層 + 池化層\n",
        "    nn.Conv2d(32, 32, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2), # img_size // 2\n",
        "    # 第三層 - 卷積層\n",
        "    nn.Conv2d(32, 64, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    # 第四層 - 卷積層 + 池化層\n",
        "    nn.Conv2d(64, 64, 3, padding='same'),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2), # img_size // 2\n",
        "    # 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64*8*8, 10)\n",
        ")\n",
        "print(cnn_model)"
      ],
      "metadata": {
        "id": "tCWonz35hXat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 32, 32)\n",
        "print(cnn_model(inputs).shape)"
      ],
      "metadata": {
        "id": "JDNiyN1vh4qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, loss_fn, train_dataloader, val_dataloader):\n",
        "    # 訓練一輪\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_train_correct = 0\n",
        "    for x, y in tqdm(train_dataloader, leave=False):\n",
        "        optimizer.zero_grad() # 梯度歸零\n",
        "        x, y = x.to(device), y.to(device) # 將資料移至GPU\n",
        "        y_pred = model(x) # 計算預測值\n",
        "        loss = loss_fn(y_pred, y) # 計算誤差\n",
        "        loss.backward() # 反向傳播計算梯度\n",
        "        optimizer.step() # 更新模型參數\n",
        "        total_train_loss += loss.item()\n",
        "        # 利用argmax計算最大值是第n個類別，與解答比對是否相同\n",
        "        total_train_correct += ((y_pred.argmax(dim=1) == y).sum().item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    avg_train_acc = total_train_correct / len(train_dataloader.dataset)\n",
        "\n",
        "    return avg_train_loss, avg_train_acc\n",
        "\n",
        "def test_epoch(model, loss_fn, val_dataloader):\n",
        "    # 驗證一輪\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    total_val_correct = 0\n",
        "    # 關閉梯度計算以加速\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            total_val_loss += loss.item()\n",
        "            # 利用argmax計算最大值是第n個類別，與解答比對是否相同\n",
        "            total_val_correct += ((y_pred.argmax(dim=1) == y).sum().item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    avg_val_acc = total_val_correct / len(val_dataloader.dataset)\n",
        "\n",
        "    return avg_val_loss, avg_val_acc\n",
        "\n",
        "def run(epochs, model, optimizer, loss_fn, train_loader, valid_loader, verbose=1):\n",
        "    train_loss_log = []\n",
        "    val_loss_log = []\n",
        "    train_acc_log = []\n",
        "    val_acc_log = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        avg_train_loss, avg_train_acc = train_epoch(model, optimizer, loss_fn, train_loader, valid_loader)\n",
        "        avg_val_loss, avg_val_acc = test_epoch(model, loss_fn, valid_loader)\n",
        "        train_loss_log.append(avg_train_loss)\n",
        "        val_loss_log.append(avg_val_loss)\n",
        "        train_acc_log.append(avg_train_acc)\n",
        "        val_acc_log.append(avg_val_acc)\n",
        "        if verbose == 1:\n",
        "            print(f'Epoch: {epoch}, Train Loss: {avg_train_loss:.3f}, Val Loss: {avg_val_loss:.3f} \\\n",
        "    | Train Acc: {avg_train_acc:.3f}, Val Acc: {avg_val_acc:.3f}')\n",
        "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log"
      ],
      "metadata": {
        "id": "szuo4pfjiRjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkrKrXctigSI"
      },
      "source": [
        "## 開始訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "print('Training DNN model')\n",
        "dnn_model = dnn_model.to(device)\n",
        "optimizer = torch.optim.Adam(dnn_model.parameters(), learning_rate)\n",
        "dnn_history = run(20, dnn_model, optimizer, loss_fn, train_loader, test_loader)\n",
        "\n",
        "print('Training CNN model')\n",
        "cnn_model = cnn_model.to(device)\n",
        "optimizer = torch.optim.Adam(cnn_model.parameters(), learning_rate)\n",
        "cnn_history = run(20, cnn_model, optimizer, loss_fn, train_loader, test_loader)"
      ],
      "metadata": {
        "id": "rnNsuL27jBOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkvF_ek87SFe"
      },
      "source": [
        "## 測試資料"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    x, y = test_ds[0]\n",
        "    x = x.to(device)\n",
        "    y_pred = cnn_model(x.unsqueeze(0))\n",
        "    print('y_pred.      : ', y_pred)\n",
        "    print('y_pred.argmax: ', y_pred.argmax(dim=1))\n",
        "    print('y            : ', y)"
      ],
      "metadata": {
        "id": "JdsQNsf1l9Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_loss, dnn_acc = test_epoch(dnn_model, loss_fn, test_loader)\n",
        "cnn_loss, cnn_acc = test_epoch(cnn_model, loss_fn, test_loader)"
      ],
      "metadata": {
        "id": "smxCixOSmVik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6OaWCuWimfe"
      },
      "source": [
        "## 訓練結果視覺化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEj3hkCJZqFf"
      },
      "outputs": [],
      "source": [
        "history_list = [cnn_history, dnn_history]\n",
        "history_train_acc = [\"cnn_train_acc\", \"dnn_train_acc\"]\n",
        "history_valid_acc = [\"cnn_valid_acc\", \"dnn_valid_acc\"]\n",
        "history_train_loss = [\"cnn_train_loss\", \"dnn_train_loss\"]\n",
        "history_valid_loss = [\"cnn_valid_loss\", \"dnn_valid_loss\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "\n",
        "# training loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for each_his, each_train, each_valid in zip(history_list,\n",
        "                                            history_train_loss,\n",
        "                                            history_valid_loss):\n",
        "    l_x = len(each_his[0])\n",
        "    plt.plot(np.arange(l_x), each_his[0], label=each_train)\n",
        "    plt.plot(np.arange(l_x), each_his[2], label=each_valid)\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')\n",
        "\n",
        "# training acc\n",
        "plt.subplot(1, 2, 2)\n",
        "for each_his, each_train, each_valid in zip(history_list,\n",
        "                                            history_train_acc,\n",
        "                                            history_valid_acc):\n",
        "    l_x = len(each_his[0])\n",
        "    plt.plot(np.arange(l_x), each_his[1], label=each_train)\n",
        "    plt.plot(np.arange(l_x), each_his[3], label=each_valid)\n",
        "plt.legend(loc='best')\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dPPPzSE5mnrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOx4z6T04-wc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}