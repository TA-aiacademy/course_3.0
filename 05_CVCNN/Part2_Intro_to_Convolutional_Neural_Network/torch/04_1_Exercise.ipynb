{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVehH4MNhbTP"
      },
      "source": [
        "# **CNN 練習**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Q6g2Bfu6hB"
      },
      "source": [
        "## 匯入所需套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj9IXN4gJ-Jd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "5diKnprkdk8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awautmYIh4a2"
      },
      "source": [
        "## Cifar10 資料讀入及前處理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKC4TPyHX5NE"
      },
      "outputs": [],
      "source": [
        "train_ds = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=T.ToTensor(),\n",
        ")\n",
        "test_ds = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=T.ToTensor(),\n",
        ")\n",
        "BATCH_SIZE = 512\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
        "                                           pin_memory=True,\n",
        "                                           shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE,\n",
        "                                         pin_memory=True,\n",
        "                                         shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqCH66zEiJ8m"
      },
      "source": [
        "## 模型定義\n",
        "- 試著建立圖中的模型架構 (NOTE: Pytorch使用channel first順序)\n",
        "\n",
        "e.g: (None, 32, 32, 3) -> (None, 3, 32, 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnoR5-IgJ-Jj"
      },
      "source": [
        "![image](https://hackmd.io/_uploads/By2IG1PL6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cZSnAQjX-M_"
      },
      "outputs": [],
      "source": [
        "'''在__________填入正確的參數讓產生的卷積影像大小不變吧'''\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # 建立卷積層，設定 32 個 3*3 的filters\n",
        "    # 設定 padding，讓卷積運算，產生的卷積影像大小不變\n",
        "    # 所有激活函數都設定為 ReLU\n",
        "    nn.Conv2d(in_channels='______', out_channels='______', kernel_size='______', padding='______'),\n",
        "    nn.'______',\n",
        "    nn.Dropout(p=0.25),\n",
        "    # 第二層 - 卷積層 (3x3 的 filters) + 池化層\n",
        "    nn.Conv2d('______', '______', '______', padding='______'),\n",
        "    nn.'______',\n",
        "    nn.MaxPool2d(2),\n",
        "    # 第三層 - 卷積層 (3x3 的 filters)\n",
        "    nn.Conv2d('______', '______', '______', padding='______'),\n",
        "    nn.'______',\n",
        "    # 第四層 - 卷積層 (3x3 的 filters) + 池化層\n",
        "    nn.Conv2d('______', '______', '______', padding='______'),\n",
        "    nn.'______',\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Dropout(p=0.25),\n",
        "\n",
        "    # 建立分類模型 (MLP) : 平坦層 + 隱藏層 (512 神經元, ReLU 為激活函數) + 輸出層 (10)\n",
        "    nn.Flatten(),\n",
        "    nn.Linear('______', '______'),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.25),\n",
        "    nn.Linear('______', 10)\n",
        ")\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32), device=device)"
      ],
      "metadata": {
        "id": "uxhZUdHOdDHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, loss_fn, train_dataloader, val_dataloader):\n",
        "    # 訓練一輪\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_train_correct = 0\n",
        "    for x, y in tqdm(train_dataloader, leave=False):\n",
        "        optimizer.zero_grad() # 梯度歸零\n",
        "        x, y = x.to(device), y.to(device) # 將資料移至GPU\n",
        "        y_pred = model(x) # 計算預測值\n",
        "        loss = loss_fn(y_pred, y) # 計算誤差\n",
        "        loss.backward() # 反向傳播計算梯度\n",
        "        optimizer.step() # 更新模型參數\n",
        "        total_train_loss += loss.item()\n",
        "        total_train_correct += ((y_pred.argmax(dim=1) == y).sum().item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    avg_train_acc = total_train_correct / len(train_dataloader.dataset)\n",
        "\n",
        "    return avg_train_loss, avg_train_acc\n",
        "\n",
        "def test_epoch(model, loss_fn, val_dataloader):\n",
        "    # 驗證一輪\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    total_val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            total_val_loss += loss.item()\n",
        "            total_val_correct += ((y_pred.argmax(dim=1) == y).sum().item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    avg_val_acc = total_val_correct / len(val_dataloader.dataset)\n",
        "\n",
        "    return avg_val_loss, avg_val_acc\n",
        "\n",
        "def run(epochs, model, optimizer, loss_fn, train_loader, valid_loader):\n",
        "    train_loss_log = []\n",
        "    val_loss_log = []\n",
        "    train_acc_log = []\n",
        "    val_acc_log = []\n",
        "    best_val_loss = np.inf\n",
        "    patience = 5\n",
        "    stop_counter = 0\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        avg_train_loss, avg_train_acc = train_epoch(model, optimizer, loss_fn, train_loader, valid_loader)\n",
        "        avg_val_loss, avg_val_acc = test_epoch(model, loss_fn, valid_loader)\n",
        "        train_loss_log.append(avg_train_loss)\n",
        "        val_loss_log.append(avg_val_loss)\n",
        "        train_acc_log.append(avg_train_acc)\n",
        "        val_acc_log.append(avg_val_acc)\n",
        "        print(f'Epoch: {epoch}, Train Loss: {avg_train_loss:.3f}, Val Loss: {avg_val_loss:.3f} \\\n",
        "    | Train Acc: {avg_train_acc:.3f}, Val Acc: {avg_val_acc:.3f}')\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best.pth')\n",
        "            stop_counter = 0\n",
        "        else:\n",
        "            stop_counter += 1\n",
        "        if stop_counter == patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log"
      ],
      "metadata": {
        "id": "BlJ2bM_0dh4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "7OqxAAC2dtjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkrKrXctigSI"
      },
      "source": [
        "## 開始訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logs = run(20, model, optimizer, loss_fn, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "mJWnKnn_dwap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adndiw8DCNhj"
      },
      "source": [
        "## 測試資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjHZj-QRJ-Jm"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best.pth'))\n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_9DvOzzCNhk"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    img, label = test_ds[0]\n",
        "    pred = model(img.unsqueeze(0).to(device))\n",
        "    print('pred: ', pred.argmax(1))\n",
        "    print('GT:   ', label)\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsPl5i8vJ-Jn"
      },
      "outputs": [],
      "source": [
        "loss, acc = test_epoch(model, loss_fn, val_loader)\n",
        "print(f'Test Loss: {loss:.3f}, Test Acc: {acc:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD5IJzCxJ-Jn"
      },
      "outputs": [],
      "source": [
        "# inference all test_loader\n",
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "        x = x.to(device)\n",
        "        y_pred = model(x)\n",
        "        y_pred_list.append(y_pred)\n",
        "        y_true_list.append(y)\n",
        "\n",
        "y_pred_list = torch.cat(y_pred_list).argmax(1).cpu()\n",
        "y_true_list = torch.cat(y_true_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqD-crhMJ-Jn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print(f'Acc score: {accuracy_score(y_true_list, y_pred_list)}')\n",
        "print(confusion_matrix(y_true_list, y_pred_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6OaWCuWimfe"
      },
      "source": [
        "## 訓練結果視覺化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-H_2wjabXas"
      },
      "outputs": [],
      "source": [
        "train_history = ['loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
        "name_history = ['training_loss', 'val_loss', 'training_acc', 'val_acc']\n",
        "train_loss, train_acc, val_loss, val_acc = logs\n",
        "history = [train_loss, val_loss, train_acc, val_acc]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "for eachx, eachy, i in zip(history, name_history, range(4)):\n",
        "    if i % 2 == 0:\n",
        "        plt.subplot(1, 2, i//2+1)\n",
        "    l_x = len(history[0])\n",
        "    plt.plot(np.arange(l_x), history[i], label=eachy)\n",
        "    plt.legend(loc='best')\n",
        "    plt.title(eachy)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW-s3EDnJ-Jn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}