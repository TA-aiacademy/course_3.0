{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 tf.Dataset 進行完整的訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload Data\n",
    "!wget -q https://github.com/TA-aiacademy/course_3.0/releases/download/CVCNN_Data/cat_dog.zip\n",
    "!unzip -q cat_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匯入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcNYA_sz14yK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob  # 讀取特定格式路徑\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwmnpAgw2XJh"
   },
   "outputs": [],
   "source": [
    "# 建立一個字典來存放路徑跟標籤資訊\n",
    "data_dict={'file_name': [], 'type': []}\n",
    "# 只拿 train 資料中的 .jpg 檔案\n",
    "for i in glob.glob('cat_dog/train/*.jpg'):\n",
    "    # i 會類似 cat_dog/train/cat.11996.jpg\n",
    "    data_dict['file_name'].append(i)\n",
    "    # 字串處理取出檔案名稱前三個字元來判斷類別\n",
    "    animal = i.split('/')[-1][:3]\n",
    "    if animal == 'cat':\n",
    "        data_dict['type'].append(0)\n",
    "    elif animal == 'dog':\n",
    "        data_dict['type'].append(1)\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oN0L2KB3Dfe"
   },
   "outputs": [],
   "source": [
    "# 將字典轉換成 DataFrame\n",
    "datalist = pd.DataFrame(data_dict)\n",
    "shuffled_df = datalist.sample(frac=1, random_state=2)  # 打亂順序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K6UYvR7YaLfW",
    "outputId": "c234a106-534f-43a0-f038-67b8373ec6d5"
   },
   "outputs": [],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分訓練/驗證集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7J23r26aY0o"
   },
   "outputs": [],
   "source": [
    "# 切分訓練/測試資料\n",
    "train_data = shuffled_df[:500]\n",
    "val_data = shuffled_df[500:1000]\n",
    "test_data = shuffled_df[1000:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZo_Wliqcavz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def my_preprocess(img_path, img_label):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    \n",
    "    return image, tf.one_hot(img_label, depth=2)  # depth=類別數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCXPoNCkanbM"
   },
   "outputs": [],
   "source": [
    "# 使用 tf.data.Dataset 製造一個 Dataset\n",
    "train_path = train_data['file_name']\n",
    "train_label = train_data['type']\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_path, train_label))  \n",
    "train_dataset = train_dataset.map(\n",
    "    lambda train_path, train_label: my_preprocess(train_path, train_label),  # 應用資料前處理\n",
    "    num_parallel_calls=tf.data.AUTOTUNE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Crk_Z2wFb_iN"
   },
   "outputs": [],
   "source": [
    "# 使用 tf.data.Dataset 製造一個 Dataset\n",
    "val_path = val_data['file_name']\n",
    "val_label = val_data['type']\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_path, val_label))\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda val_path, val_label: my_preprocess(val_path, val_label))  # 應用資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "-bROdH7DeGyF",
    "outputId": "d6559285-649b-45da-e3b8-450864e94639"
   },
   "outputs": [],
   "source": [
    "def my_plot(datas):\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    for i,data in enumerate(datas):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(data[0].numpy().astype('uint8'))\n",
    "        plt.title(\"Label: {}\".format(data[1]), fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "my_plot(train_dataset.take(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivl7PCIu2b0d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Activation,\n",
    "                                     BatchNormalization, Flatten,\n",
    "                                     Conv2D, MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5cM_MI0cs29"
   },
   "outputs": [],
   "source": [
    "# 選擇 Keras 的 API 寫法\n",
    "inputs = Input(shape=(256, 256, 3)) #輸入資料維度\n",
    "# 前處理：隨機旋轉\n",
    "x = layers.RandomRotation(factor=(-0.3, 0.3),\n",
    "                          fill_mode=\"reflect\")(inputs)\n",
    "# 第一層\n",
    "# 建立卷積層，設定32個3*3的filters\n",
    "# 設定ReLU為激活函數。\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "\n",
    "# 第二層 - 卷積層 + 池化層\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# 第三層 - 卷積層\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "# 第四層 - 卷積層 + 池化層\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# 建立分類模型 (MLP) : 平坦層 + 輸出層 (10)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(2, activation='softmax')(x) # 輸出類別數量\n",
    "\n",
    "\n",
    "cnn_model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljoiFhNTeVCK",
    "outputId": "e4b869b2-1923-4bf7-be82-e0096b689410"
   },
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEeddJnHdz5R"
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzYaqb0ig46b",
    "outputId": "f8595952-62d4-4f28-8da2-b3cee4193d05"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataset_batch = train_dataset.batch(batch_size)  # dataset 參考 DL par4 Custom_dataset\n",
    "val_dataset_batch = val_dataset.batch(batch_size)  # dataset 參考 DL par4 Custom_dataset\n",
    "\n",
    "cnn_model.fit(train_dataset_batch,  # 訓練一圈次數=15000/128 =118圈\n",
    "              validation_data=val_dataset_batch,\n",
    "              epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp9kHuFJjWQX"
   },
   "source": [
    "## 測試資料 (模擬沒有答案的測試資料)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def my_preprocess_test(img_path):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    \n",
    "    return image  # depth=類別數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 tf.data.Dataset 製造一個 Dataset\n",
    "test_path = test_data['file_name']\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_path))  \n",
    "test_dataset = test_dataset.map(lambda test_path: my_preprocess_test(test_path))  # 應用資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn_model.predict(test_dataset.batch(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析模型預測結果，並填入Dataframe中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditc_label = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'file_name': test_path, 'prediction': preditc_label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
