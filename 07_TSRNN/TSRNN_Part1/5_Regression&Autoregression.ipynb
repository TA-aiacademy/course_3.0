{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mB0In5zYtQw"
      },
      "source": [
        "# 5_Regression&Autoregression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8CtSi-YtQ1"
      },
      "source": [
        "ä»¥ä¸Šæˆ‘å€‘æœ‰äº†data,ä¸¦çµ„æˆdata loaderï¼Œæˆ‘å€‘ä½¿ç”¨å‰›å‰›loaderå¯ä»¥ä¾†è¨“ç·´ä¸€äº›æ¨¡å‹ã€‚\n",
        "\n",
        "é€™é‚Šæˆ‘å€‘ç”¨äº›ç°¡å–®çš„è¿´æ­¸æ¨¡å‹ä¾†è©¦è©¦çœ‹:\n",
        "- Linear Regression\n",
        "- Autoregression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmcMo4yAYtQ2"
      },
      "source": [
        "**å…ˆimportä¸€äº›å¥—ä»¶**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buzO-o1yYtQ3"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly import express as px\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.data as tfd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colabä½¿ç”¨è¦æ›´æ›statsmodelsç‰ˆæœ¬ ï¼Œå®‰è£å®Œè«‹é‡æ–°å•Ÿå‹•åŸ·è¡Œéšæ®µ\n",
        "!pip uninstall -y statsmodels\n",
        "!pip install statsmodels==0.11.1"
      ],
      "metadata": {
        "id": "T19LAWQOJj63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU9iLRCiYtQ6"
      },
      "source": [
        "**çµ¦ä¸€äº›å¿…è¦function: ç•«åœ–ã€åˆæˆè³‡æ–™ç”¢ç”Ÿã€window data loaderç”¢ç”Ÿã€è©•ä¼°function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKMh4kQyYtQ7"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series, start=0, end=None, labels=None, title=None):\n",
        "    #  Visualizes time series data\n",
        "    # Args:\n",
        "    #  time (array of int) - æ™‚é–“é», é•·åº¦ç‚ºT\n",
        "    #  series (list of array of int) - æ™‚é–“é»å°æ‡‰çš„è³‡æ–™åˆ—è¡¨ï¼Œåˆ—è¡¨å…§æ™‚é–“åºåˆ—æ•¸é‡ç‚ºDï¼Œ\n",
        "    #                                  æ¯ç­†è³‡æ–™é•·åº¦ç‚ºTï¼Œè‹¥éç‚ºåˆ—è¡¨å‰‡è½‰ç‚ºåˆ—è¡¨\n",
        "    #  start (int) - é–‹å§‹çš„è³‡æ–™åº(ç¬¬å¹¾ç­†)\n",
        "    #  end (int) -   çµæŸç¹ªè£½çš„è³‡æ–™åº(ç¬¬å¹¾ç­†)\n",
        "    #  labels (list of strings)- å°æ–¼å¤šæ™‚é–“åºåˆ—æˆ–å¤šç¶­åº¦çš„æ¨™è¨»\n",
        "    #  title (string)- åœ–ç‰‡æ¨™é¡Œ\n",
        "\n",
        "    # è‹¥è³‡æ–™åªæœ‰ä¸€ç­†ï¼Œå‰‡è½‰ç‚ºlist\n",
        "    if type(series) != list:\n",
        "        series = [series]\n",
        "\n",
        "    if not end:\n",
        "        end = len(series[0])\n",
        "\n",
        "    if labels:\n",
        "        # è¨­ç«‹dictionary, è®“plotlyç•«è¨Šè™Ÿç·šæ™‚å¯ä»¥æ¨™è¨»label\n",
        "        dictionary = {\"time\": time}\n",
        "        for idx, l in enumerate(labels):\n",
        "            # æˆªæ–·è³‡æ–™ï¼Œä¿ç•™æƒ³çœ‹çš„éƒ¨åˆ†ï¼Œä¸¦åˆ†æ®µç´€éŒ„æ–¼dictionaryä¸­\n",
        "            dictionary.update({l: series[idx][start:end]})\n",
        "        # ç•«è¨Šè™Ÿç·š\n",
        "        fig = px.line(dictionary,\n",
        "                      x=\"time\",\n",
        "                      y=list(dictionary.keys())[1:],\n",
        "                      width=1000,\n",
        "                      height=400,\n",
        "                      title=title)\n",
        "    else:\n",
        "        # ç•«è¨Šè™Ÿç·š\n",
        "        fig = px.line(x=time, y=series, width=1000, height=400, title=title)\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "# åˆæˆè³‡æ–™ç”Ÿæˆ\n",
        "def trend(time, slope=0):\n",
        "    # ç”¢ç”Ÿåˆæˆæ°´å¹³ç›´ç·šè³‡æ–™ï¼Œå…¶é•·åº¦èˆ‡æ™‚é–“ç­‰é•·ï¼Œç›´ç·šè¶¨å‹¢èˆ‡è¨­å®šslopeç›¸åŒ\n",
        "    # Args:\n",
        "    #  time (array of int) - æ™‚é–“é», é•·åº¦ç‚ºT\n",
        "    #  slope (float) - è¨­å®šè³‡æ–™çš„å‚¾æ–œç¨‹åº¦èˆ‡æ­£è² \n",
        "    # Returns:\n",
        "    #  series (array of float) -  ç”¢å‡ºslope èˆ‡è¨­å®šç›¸åŒçš„ä¸€æ¢ç·š\n",
        "\n",
        "    series = slope * time\n",
        "\n",
        "    return series\n",
        "\n",
        "\n",
        "def seasonal_pattern(season_time, pattern_type='triangle'):\n",
        "    # ç”¢ç”ŸæŸå€‹ç‰¹å®špatternï¼Œ\n",
        "    # Args:\n",
        "    #  season_time (array of float) - å‘¨æœŸå…§çš„æ™‚é–“é», é•·åº¦ç‚ºT\n",
        "    #  pattern_type (str) -  é€™é‚Šæä¾›triangleèˆ‡cosine\n",
        "    # Returns:\n",
        "    #  data_pattern (array of float) -  æ ¹æ“šè‡ªè¨‚å‡½å¼ç”¢å‡ºç‰¹å®šçš„pattern\n",
        "\n",
        "    # ç”¨ç‰¹å®šfunctionç”Ÿæˆpattern\n",
        "    if pattern_type == 'triangle':\n",
        "        data_pattern = np.where(season_time < 0.5,\n",
        "                                season_time*2,\n",
        "                                2-season_time*2)\n",
        "    if pattern_type == 'cosine':\n",
        "        data_pattern = np.cos(season_time*np.pi*2)\n",
        "\n",
        "    return data_pattern\n",
        "\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=30, pattern_type='triangle'):\n",
        "    # Repeats the same pattern at each period\n",
        "    # Args:\n",
        "    #   time (array of int) - æ™‚é–“é», é•·åº¦ç‚ºT\n",
        "    #   period (int) - é€±æœŸé•·åº¦ï¼Œå¿…å°æ–¼T\n",
        "    #   amplitude (float) - åºåˆ—å¹…åº¦å¤§å°\n",
        "    #   phase (int) - ç›¸ä½ï¼Œç‚ºéç§»é‡ï¼Œæ­£çš„å‘å·¦(æå‰)ã€è² çš„å‘å³(å»¶å¾Œ)\n",
        "    #   pattern_type (str) -  é€™é‚Šæä¾›triangleèˆ‡cosine\n",
        "    # Returns:\n",
        "    #   data_pattern (array of float) - æœ‰æŒ‡å®šå‘¨æœŸã€æŒ¯å¹…ã€ç›¸ä½ã€patternå¾Œçš„time series\n",
        "\n",
        "    # å°‡æ™‚é–“ä¾é€±æœŸé‡ç½®ç‚º0\n",
        "    season_time = ((time + phase) % period) / period\n",
        "\n",
        "    # ç”¢ç”Ÿé€±æœŸæ€§è¨Šè™Ÿä¸¦ä¹˜ä¸Šå¹…åº¦\n",
        "    data_pattern = amplitude * seasonal_pattern(season_time, pattern_type)\n",
        "\n",
        "    return data_pattern\n",
        "\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    # åˆæˆé›œè¨Šï¼Œé€™é‚Šç”¨é«˜æ–¯é›œè¨Šï¼Œæ©Ÿç‡å¯†åº¦ç‚ºå¸¸æ…‹åˆ†å¸ƒ\n",
        "    # Args:\n",
        "    #   time (array of int) - æ™‚é–“é», é•·åº¦ç‚ºT\n",
        "    #   noise_level (float) - é›œè¨Šå¤§å°\n",
        "    #   seed (int) - åŒæ¨£çš„seedå¯ä»¥é‡ç¾åŒæ¨£çš„é›œè¨Š\n",
        "    # Returns:\n",
        "    #   noise (array of float) - é›œè¨Šæ™‚é–“åºåˆ—\n",
        "\n",
        "    # åšä¸€å€‹åŸºæ–¼æŸå€‹seedçš„é›œè¨Šç”Ÿæˆå™¨\n",
        "    rnd = np.random.RandomState(seed)\n",
        "\n",
        "    # ç”Ÿèˆ‡timeåŒé•·åº¦çš„é›œè¨Šï¼Œä¸¦ä¸”ä¹˜ä¸Šé›œè¨Šå¤§å° (ä¸ä¹˜çš„è©±ï¼Œæ¨™æº–å·®æ˜¯1)\n",
        "    noise = rnd.randn(len(time)) * noise_level\n",
        "\n",
        "    return noise\n",
        "\n",
        "\n",
        "def toy_generation(time=np.arange(4 * 365),\n",
        "                   bias=500.,\n",
        "                   slope=0.1,\n",
        "                   period=180,\n",
        "                   amplitude=40.,\n",
        "                   phase=30,\n",
        "                   pattern_type='triangle',\n",
        "                   noise_level=5.,\n",
        "                   seed=2022):\n",
        "    signal_series = bias\\\n",
        "                  + trend(time, slope)\\\n",
        "                  + seasonality(time,\n",
        "                                period,\n",
        "                                amplitude,\n",
        "                                phase,\n",
        "                                pattern_type)\n",
        "    noise_series = noise(time, noise_level, seed)\n",
        "\n",
        "    series = signal_series+noise_series\n",
        "    return series\n",
        "\n",
        "\n",
        "# Dataset\n",
        "def win_ar_ds(series, size, shift=1):\n",
        "    # è¼¸å‡ºWindow-wise Forcasting Dataset\n",
        "    # Args:\n",
        "    #   series (array of float) - æ™‚åºè³‡æ–™, é•·åº¦ç‚ºT\n",
        "    #   size (int) - Windowå¤§å°\n",
        "    #   shift (int) - æ¯å€‹windowèµ·å§‹é»é–“è·\n",
        "    # Returns:\n",
        "    #   (tf.data.Dataset(æ¯é¡åç¨±ï¼Œåˆ‡ç¢ºtypeç‚ºMapDataset)) -\n",
        "    #   - ä¸€å€‹ä¸€æ¬¡ç”Ÿä¸€å€‹windowçš„ç”Ÿæˆå™¨\n",
        "\n",
        "    ds = tfd.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(size=size+1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda ds: ds.batch(size+1))\n",
        "    return ds.map(lambda x: (x[:-1], x[-1:]))\n",
        "\n",
        "\n",
        "def regressor_ds(*regressors, series):\n",
        "    # è¼¸å‡ºWindow-wise Regressor Forcasting Dataset\n",
        "    # Args:\n",
        "    #   regressors (arguments of array of float) - å¤šå€‹è¿´æ­¸å› å­ï¼Œæ¯å€‹é•·åº¦ç‚ºT\n",
        "    #   series (array of float) - é æ¸¬å°è±¡ï¼Œé•·åº¦\n",
        "    # Returns:\n",
        "    #   (tf.data.Dataset(æ¯é¡åç¨±ï¼Œåˆ‡ç¢ºtypeç‚ºTensorSliceDataset)) -\n",
        "    #   - ä¸€æ¬¡ç”Ÿregressorså’Œtime seriesçš„dataset\n",
        "\n",
        "    ds = tfd.Dataset.from_tensor_slices((np.stack(regressors, -1), series))\n",
        "    return ds\n",
        "\n",
        "\n",
        "# è©•ä¼°function\n",
        "def MAE(pred, gt):\n",
        "    # è¨ˆç®—Mean Absolute Error\n",
        "    # Args:\n",
        "    #  pred (array of float) - é æ¸¬è³‡æ–™\n",
        "    #  gt (array of float) - ç­”æ¡ˆè³‡æ–™\n",
        "    # Returns:\n",
        "    #  è¨ˆç®—çµæœ (float)\n",
        "    return abs(pred-gt).mean()\n",
        "\n",
        "\n",
        "def MSE(pred, gt):\n",
        "    # è¨ˆç®—Mean Square Error\n",
        "    # Args:\n",
        "    #  pred (array of float) - é æ¸¬è³‡æ–™\n",
        "    #  gt (array of float) - ç­”æ¡ˆè³‡æ–™\n",
        "    # Returns:\n",
        "    #  è¨ˆç®—çµæœ (float)\n",
        "    return pow(pred-gt, 2).mean()\n",
        "\n",
        "\n",
        "def R2(pred, gt):\n",
        "    # è¨ˆç®—R square score\n",
        "    # Args:\n",
        "    #  pred (array of float) - é æ¸¬è³‡æ–™\n",
        "    #  gt (array of float) - ç­”æ¡ˆè³‡æ–™\n",
        "    # Returns:\n",
        "    #  è¨ˆç®—çµæœ (float)\n",
        "    return 1-pow(pred-gt, 2).sum()/pow(gt-gt.mean(), 2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hg1yBiFYtQ-"
      },
      "outputs": [],
      "source": [
        "def split(x, train_size):\n",
        "    return x[..., :train_size], x[..., train_size:]\n",
        "\n",
        "\n",
        "# å…ˆåˆæˆè³‡æ–™ï¼Œé‚„æœ‰ä½œè³‡æ–™åˆ†å‰²\n",
        "time = np.arange(4*365)  # å®šç¾©æ™‚é–“é»\n",
        "series_sample = toy_generation(time, pattern_type='cosine')  # é€™å°±æ˜¯æˆ‘å€‘åˆæˆå‡ºä¾†çš„è³‡æ–™\n",
        "\n",
        "time_train, time_test = split(time, 365*3)\n",
        "series_train, series_test = split(series_sample, 365*3)\n",
        "\n",
        "# å¦å¤–ä¹ŸåŠ ä¸Šè¼”åŠ©è³‡æ–™\n",
        "cos_train = seasonality(time_train, 180, 1., 30, 'cosine')\n",
        "cos_test = seasonality(time_test, 180, 1., 30, 'cosine')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf7Hx8kqYtQ-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, losses, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_mruI5NYtQ_"
      },
      "outputs": [],
      "source": [
        "# ç”¨å„ç¨®regressor predictè³‡æ–™çš„training set\n",
        "train_ds_r = regressor_ds(time_train,\n",
        "                          cos_train,\n",
        "                          series=series_train)  # åˆ‡time series\n",
        "train_loader_r = train_ds_r.cache()\\\n",
        "    .shuffle(1000).batch(32, drop_remainder=True).prefetch(-1)\n",
        "\n",
        "# ç”¨å„ç¨®regressor predictè³‡æ–™çš„testing set\n",
        "test_ds_r = regressor_ds(time_test,\n",
        "                         cos_test,\n",
        "                         series=series_test)  # åˆ‡time series\n",
        "test_loader_r = test_ds_r.batch(32).prefetch(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsGYkZHSYtRA"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader_r:\n",
        "    pass\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u71pbrmoeYv"
      },
      "outputs": [],
      "source": [
        "cos_train = seasonality(time_train, 180, 1., 45, 'cosine')\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(cos_train, 'b', linewidth=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7G-a15YtRA"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnJmC2lNYtRA"
      },
      "source": [
        "å‰é¢MLçš„èª²ç¨‹å·²ç¶“æ•™éLinear Regressionçš„èª²ç¨‹ï¼Œ\n",
        "\n",
        "å…¶ä¸­å¤šè®Šé‡è¿´æ­¸æ™‚æ˜¯é€éè½‰ç½®çŸ©é™£wèˆ‡åç§»bå¯ä»¥é æ¸¬ä¸‹å€‹æ™‚é–“é»çš„å€¼\n",
        "\n",
        "$y=w^Tx+b$\n",
        "\n",
        "é€éè¨“ç·´åƒæ•¸wèˆ‡bå¯ä»¥ä½¿ç³»çµ±æ›´åŠ èƒ½æ“¬åˆfeatureèˆ‡é æ¸¬å€¼ä¹‹é–“é—œä¿‚ã€‚\n",
        "\n",
        "<img src=https://i.imgur.com/0B4K969.png width=200 align=left>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULbe4biUYtRB"
      },
      "source": [
        "è€ŒLinear time regressionä¸­æˆ‘å€‘ä½¿ç”¨$t_{n-W:n}$ä»£å…¥input xçš„éƒ¨åˆ†ï¼Œè¨ˆç®—output $y_n$æ‡‰è©²è¦æ˜¯å¤šå°‘"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYTsY090YtRB"
      },
      "source": [
        "<img src=https://i.imgur.com/jqHvsVw.png width=500 align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsJKnu8vh1TO"
      },
      "source": [
        "è€Œåœ¨ç¤ºç¯„çš„training dataä¸­é™¤äº†time regressionæˆ‘å€‘é‚„åŠ ä¸Šcosineæ³¢å½¢ä½œç‚ºå¦ä¸€å€‹regression feature (åˆç¨±regressor)ã€‚\n",
        "\n",
        "æˆ‘å€‘çš„tæ˜¯å‰é¢```time_train```çš„éƒ¨åˆ†ï¼Œcosineæ³¢å½¢æ˜¯å‰é¢```cos_train```ï¼Œyæ˜¯å‰é¢```series_train```çš„éƒ¨åˆ†"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lUoc8KSYtRB"
      },
      "source": [
        "### Build TF2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w8M63wxYtRC"
      },
      "source": [
        "è€Œæˆ‘å€‘é€™é‚Šå¯ä»¥ç”¨ä¸€å€‹ä¸€å±¤ä¸”ç„¡activationçš„Denseå±¤ä¾†å®Œæˆé€™å€‹åŠŸèƒ½ï¼Œè€Œä¸”æˆ‘å€‘å‰é¢æœ‰å¹¾å€‹layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4WcRBw6YtRC"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=[2], data_format=\"channels_first\"),\n",
        "    layers.Dense(1, activation=None)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb9AW_HFYtRC",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "# å…±æœ‰window_size*K+1å€‹parameter å°±çœ‹è¦æ”¾å¹¾å€‹regressor,æœ€å¾Œä¸€å€‹parameteræ˜¯bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEdTdN7AYtRD"
      },
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=1e-1)\n",
        "model.compile(loss=\"mse\", optimizer=opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEuHJz_iYtRD"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg3CPRfKYtRE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_loader_r,\n",
        "    epochs=400,\n",
        "    verbose=2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='loss'),\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=20,\n",
        "            verbose=2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qb4uMiqYtRE"
      },
      "source": [
        "å¯ä»¥çœ‹ä¸€ä¸‹modelçš„weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpShItcxYtRE"
      },
      "outputs": [],
      "source": [
        "# ç¬¬ä¸€å€‹æ˜¯time trendçš„weightï¼Œç¬¬äºŒå€‹æ˜¯cosine wave çš„trend\n",
        "model.weights[0].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzvxsa4CYtRF"
      },
      "source": [
        "é€™é‚Šæ•…æ„èª¿æ•´weightçš„é †åºï¼Œä½¿å¾—å‰é¢ä¸€åŠæ˜¯linear trendç›¸é—œçš„weightï¼Œå¾Œé¢ä¸€åŠæ˜¯cosineç›¸é—œçš„weightã€‚\n",
        "\n",
        "å¯ä»¥çœ‹å‡ºé€™å…©è€…çš„é‡å€¼è·Ÿæˆ‘å€‘é è¨­çš„å¾ˆæ¥è¿‘"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tp2OMR8YtRF"
      },
      "outputs": [],
      "source": [
        "# bias\n",
        "model.weights[1].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDjgdYuNYtRF"
      },
      "source": [
        "biaså‰‡æ˜¯å¾ˆé€¼è¿‘æˆ‘å€‘é è¨­çš„level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUeaJZYiYtRG"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Jr6kjdYtRG"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_loader_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG62QnufYtRH"
      },
      "source": [
        "åŸºæœ¬ä¸Šå°±æ˜¯å¾ˆåœ“æ»‘çš„ç·šï¼Œå› ç‚ºæˆ‘å€‘åªç”¨äº†linear trendä»¥åŠcosineè€Œå·²\n",
        "\n",
        "çµæœå°±é‚„å¥½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m02RLq1YtRG"
      },
      "outputs": [],
      "source": [
        "forcast = model.predict(test_loader_r)[:, 0]\n",
        "time_for_view = time_test\n",
        "\n",
        "plot_series(time_for_view,\n",
        "            [forcast, series_test],\n",
        "            labels=['prediction', 'ground truth'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi8x49FLgQNa"
      },
      "source": [
        "é€™é‚Šæˆ‘å€‘æŠŠé‚£äº›è¨“ç·´å¥½çš„weightå¥—ä¸Šå€‹åˆ¥regressorï¼Œä¸¦æ‰£é™¤æ‰è¨“ç·´å¥½çš„biasçš„å½±éŸ¿\n",
        "\n",
        "ç•«å‡ºä¾†çœ‹çœ‹:\n",
        "\n",
        "$trend[t]=time[t]*weight_{0}$\n",
        "\n",
        "$seasonality[t]=cos[t]*weight_{1}$\n",
        "\n",
        "$y'[t]=y[t]-bias$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4Zj_j4te70x"
      },
      "outputs": [],
      "source": [
        "plot_series(time_for_view,\n",
        "            [time_test*model.weights[0][0].numpy(),\n",
        "             cos_test*model.weights[0][1].numpy(),\n",
        "             series_test-model.weights[1][0].numpy()],\n",
        "            labels=['weighted time', 'weighted cosine', 'ground truth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr7goZPvYtRH"
      },
      "outputs": [],
      "source": [
        "# ç®—å‡ºR2 scoreä¾†çœ‹çœ‹\n",
        "R2(forcast, series_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkxYNtV3YtRH"
      },
      "source": [
        "### Exercise\n",
        "è«‹è©¦è©¦çœ‹ä¸åŒregressorå°regressionçš„å½±éŸ¿ï¼Œå¯ä»¥æ³¨æ„åˆ°å°weightè·Ÿbiasçš„å½±éŸ¿\n",
        "\n",
        "e.g. å°‡```pattern_type```æ›æˆ```triangle```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IEsyU2lYtRH"
      },
      "source": [
        "## Autoregressive Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDr-WShRYtRI"
      },
      "source": [
        "Autoregressionå‡è¨­ç¾åœ¨çš„åºåˆ—èˆ‡å‰é¢æœ‰é™å€‹æ™‚é–“é»çš„æ•¸å€‹åºåˆ—æœ‰é—œï¼š\n",
        "\n",
        "$y_t=w_0 y_{t-1}+w_1 y_{t-2}+...+ w_T y_{t-T} $\n",
        "\n",
        "å…¶å¯¦å°±æ˜¯å°å‰é¢çš„æ™‚é–“é»å¥—ç”¨ä¸€å€‹å›ºå®šçš„åŠ æ¬Šå’Œï¼Œè€Œé€™å€‹åŠ æ¬Šçš„æ¬Šé‡æ˜¯å¯ä»¥è¨“ç·´çš„ã€‚\n",
        "\n",
        "ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯å¥—ç”¨æŸå€‹æ³¢å½¢ä½œ1D convolutionä¾†é æ¸¬æœªä¾†åºåˆ—ï¼Œé€™æ¨£åœ¨æœ‰ä¸€å®šå‘¨æœŸæ€§æ™‚æ˜¯æœ‰å¹«åŠ©çš„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzJSngVAYtRI"
      },
      "outputs": [],
      "source": [
        "# é€™é‚Šè¦ç”¨ä¸ä¸€æ¨£çš„dataset\n",
        "window_size = 7\n",
        "\n",
        "# ç”¨è³‡æ–™predictè³‡æ–™çš„training set\n",
        "train_ds = win_ar_ds(series_train, size=window_size)  # åˆ‡time series\n",
        "train_loader = train_ds.cache()\\\n",
        "    .shuffle(1000).batch(32, drop_remainder=True).prefetch(-1)\n",
        "\n",
        "# ç”¨è³‡æ–™predictè³‡æ–™çš„testing set\n",
        "test_ds = win_ar_ds(series_test, size=window_size)  # åˆ‡time series\n",
        "test_loader = test_ds.batch(32).prefetch(-1)\n",
        "for x, y in train_loader:\n",
        "    pass\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmKyO7qNYtRI"
      },
      "source": [
        "### Build TF2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lYsF7VsYtRJ"
      },
      "source": [
        "è€Œæˆ‘å€‘é€™é‚Šå¯ä»¥ç”¨ä¸€å€‹ä¸€å±¤ä¸”ç„¡activationçš„Denseå±¤ä¾†å®Œæˆä¸€å€‹AR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHL6umB3YtRJ"
      },
      "outputs": [],
      "source": [
        "model_ar = models.Sequential([\n",
        "    layers.Dense(1, input_shape=[window_size], activation=None)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oblTI6jCYtRJ"
      },
      "outputs": [],
      "source": [
        "model_ar.summary()\n",
        "# å…±æœ‰window_size+1å€‹parameter,æœ€å¾Œä¸€å€‹parameteræ˜¯bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo-8PxgYYtRJ"
      },
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=1e-2)\n",
        "model_ar.compile(loss=\"mse\", optimizer=opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQDt-FFYtRK"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnQjmYkjYtRK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history = model_ar.fit(\n",
        "    train_loader,\n",
        "    epochs=400,\n",
        "    verbose=2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='loss'),\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=20,\n",
        "            verbose=2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D1N7lwiYtRK"
      },
      "source": [
        "å¯ä»¥çœ‹ä¸€ä¸‹modelçš„weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DULfcM7yYtRL"
      },
      "outputs": [],
      "source": [
        "# weight\n",
        "plt.bar(np.arange(window_size), model_ar.weights[0].numpy().squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMtyzxSrYtRL"
      },
      "source": [
        "å®ƒçš„weightèˆ‡AutoCorrelated Functionæ­£ç›¸é—œï¼Œä¹Ÿå°±æ˜¯å‰é¢è¬›çš„convolutionæ™‚ç”¨åˆ°çš„æ³¢å½¢ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTIU4AgtYtRL"
      },
      "outputs": [],
      "source": [
        "# bias\n",
        "model_ar.weights[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7smqERA9YtRL"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz-oFgSbYtRM"
      },
      "outputs": [],
      "source": [
        "model_ar.evaluate(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roqXpsadYtRM"
      },
      "outputs": [],
      "source": [
        "forcast = model_ar.predict(test_loader)[:, 0]\n",
        "ground_truth_for_view = series_test[window_size:]\n",
        "time_for_view = time_test[window_size:]\n",
        "\n",
        "plot_series(time_for_view,\n",
        "            [forcast, ground_truth_for_view],\n",
        "            labels=['prediction', 'ground truth'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llKCeRqDYtRM"
      },
      "source": [
        "é€™é‚Šæˆ‘å€‘ä½¿ç”¨autoregressionçš„çµæœï¼Œå› ç‚ºnoiseç„¡æ³•æ“¬å’Œï¼Œæ‰€ä»¥æœƒå—åˆ°å¹²æ“¾\n",
        "\n",
        "è€Œä¸”è·ŸSESå¾ˆåƒï¼Œå¦‚æœé ä¼°çš„æ™‚é–“å¾ˆé•·ï¼Œå‰‡é ä¼°è¶Šä¾†è¶Šä¸å‡†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVKvuebUYtRM"
      },
      "outputs": [],
      "source": [
        "R2(forcast, ground_truth_for_view)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6dhkhpjYtRN"
      },
      "source": [
        "## Autoregressive Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtqswrubYtRN"
      },
      "source": [
        "ç•¶è³‡æ–™æœ‰çŸ­æœŸçš„autoregressiveæ•ˆæ‡‰æ™‚ï¼Œç›®å‰è³‡æ–™æœƒå—éå¾€è³‡æ–™å½±éŸ¿è¼ƒå¤šã€‚\n",
        "\n",
        "æˆ‘å€‘æ‹¿ä¸€å€‹autoregressive kernelèˆ‡ä¸€çµ„èµ·å§‹çš„æ•¸å€¼ä¾†è©¦è©¦çœ‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8zodJ3rYtRN"
      },
      "outputs": [],
      "source": [
        "kernal = np.array([-0.5, 0.4, -0.3, 0.4, 0.5])\n",
        "kernal = kernal/np.linalg.norm(kernal)\n",
        "\n",
        "series = [2, 2, 2, 2, 2]\n",
        "# series = [1, 2, 3, 4, 5]\n",
        "# series = [5, 4, 3, 2, 1]\n",
        "for i in range(80):\n",
        "    last = np.array(series[-5:])\n",
        "    series.append(kernal@last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjRU9Py-YtRN"
      },
      "outputs": [],
      "source": [
        "plot_series(np.arange(len(series)), np.array(series))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WUmjLCDYtRO"
      },
      "source": [
        "å…¶å¯¦å¯ä»¥çœ‹å‡ºä¾†ï¼Œautoregressionçµæœåœ¨å“ªç¨®èµ·å§‹ç‹€æ…‹éƒ½ç„¡æ‰€è¬‚ï¼Œåªè¦ä¸æ˜¯å…¨ç‚º0ï¼Œåªè¦weightä¸€æ¨£æœ€å¾Œéƒ½æœƒconvergeåˆ°ä¸€æ¨£çš„pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3F6jwA2oeY6"
      },
      "source": [
        "## Autoregressive Integrated Moving Average (ARIMA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXMvJGVaoeY6"
      },
      "source": [
        "é€™é‚ŠAR model å¯å»¶ä¼¸å‡ºARMA, ARIMAæˆ–è€…æ›´å¾Œé¢çš„SARIMA modelã€‚\n",
        "\n",
        "ARMAå°±æ˜¯åˆ†æˆå…©å€‹AR modelå°è³‡æ–™åšæ“¬åˆï¼š\n",
        "1. ç¬¬ä¸€éƒ¨åˆ†æ˜¯åštime seriesçš„AR modelï¼›\n",
        "2. å¦ä¸€éƒ¨åˆ†æ˜¯residual çš„AR model\n",
        "\n",
        "$F_ğ‘›=ğ›½_1 ğ‘¦_{ğ‘›âˆ’1}+ğ›½_2 ğ‘¦_{ğ‘›âˆ’2}+â€¦+ğ›½_ğ‘ ğ‘¦_{ğ‘›âˆ’ğ‘}\\ (part 1)$\n",
        "\n",
        "  $+ğœ–_ğ‘›+ğœƒ_1 ğœ–_{ğ‘›âˆ’1}+ğœƒ_2 ğœ–_{ğ‘›âˆ’2}+â€¦+ğœƒ_ğ‘ ğœ–_{ğ‘›âˆ’ğ‘}\\ (part 2)$\n",
        "  \n",
        "é€™residual term æ˜¯å¾åŸseriesæ‰£æ‰AR model forecastçš„çµæœç”¢ç”Ÿçš„åºåˆ—\n",
        "\n",
        "(è¼ƒç‚ºç°¡å–®çš„ç‰ˆæœ¬æ˜¯ç”¨moving averageå–ä»£AR modelï¼Œå¾Œä¾†æ¯”è¼ƒå¸¸ç”¨AR modelåšç¬¬ä¸€éšæ®µforecast)\n",
        "\n",
        "$ğœ–_ğ‘›=ğ‘¦_ğ‘›âˆ’ ğ›½_1 ğ‘¦_{ğ‘›âˆ’1}+ğ›½_2 ğ‘¦_{ğ‘›âˆ’2}+â€¦+ğ›½_ğ‘ ğ‘¦_{ğ‘›âˆ’ğ‘} $\n",
        "\n",
        "\n",
        "<img src=https://i.imgur.com/x4oHilw.png width=400 align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb3myl5uoeY7"
      },
      "source": [
        "é‚£æ•´é«”æ¨¡å‹å‰‡æ˜¯ç”±åŸseriesç¶“éARæ¨¡å‹å¾—åˆ°AR forecastï¼Œä¸¦èˆ‡åŸseriesç›¸æ¸›å¾—åˆ°residual\n",
        "residual å†ç¶“ç”±MAæ¨¡å‹(part2)å¾—åˆ°MA forecast\n",
        "æœ€å¾Œé€™å…©å€‹forecaståŠ åœ¨ä¸€èµ·å°±æ˜¯ARMA modelçš„é æ¸¬\n",
        "\n",
        "è‡³æ–¼è¶…åƒæ•¸pèˆ‡qå‰‡æ˜¯éœ€è¦ä¸€äº›å°dataçš„äº†è§£æˆ–å˜—è©¦å–å¾—æœ€ä½³è§£ã€‚\n",
        "\n",
        "<img src=https://i.imgur.com/HCtJarZ.png width=400 align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15QbppOvoeY7"
      },
      "source": [
        "ARIMAå°±æ˜¯å…ˆåšå®Œdifferencingå†åšå‰é¢çš„ARMAï¼ŒDifferencingä¹‹å¾Œå¯ä»¥å»æ‰trendï¼Œæ‰€ä»¥è¦æ±‚åªéœ€è¦ä¿æŒä¸è¦æœ‰seasonalityå°±å¥½ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRkZYyLGoeY7"
      },
      "outputs": [],
      "source": [
        "# ç”¨Sequencialæ–¹å¼ä¹Ÿçµ„æˆMA model\n",
        "# é€™é‚Šåƒæ•¸æ•¸é‡qä½¿ç”¨èˆ‡AR modelä¸€æ¨£\n",
        "model_ma = models.Sequential([\n",
        "    layers.Dense(1, input_shape=[window_size], activation=None, use_bias=False)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYcw71OuoeY7"
      },
      "outputs": [],
      "source": [
        "model_ma.summary()\n",
        "# å…±æœ‰window_sizeå€‹parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNFGlFU2oeY7"
      },
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=1e-2)\n",
        "model_ma.compile(loss=\"mse\", optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQVM1UlSoeY7"
      },
      "outputs": [],
      "source": [
        "# é€™é‚Šè¦é‡åšä¸€å€‹dataset\n",
        "\n",
        "# å–å‡ºresidual\n",
        "residual_train = series_train[window_size:]\\\n",
        "    - model_ar.predict(train_ds.batch(32)).squeeze()\n",
        "residual_test = series_test[window_size:]\\\n",
        "    - model_ar.predict(test_ds.batch(32)).squeeze()\n",
        "\n",
        "# çµ„æˆdataloader\n",
        "residual_train_loader = win_ar_ds(residual_test, size=window_size)\\\n",
        "    .cache().shuffle(1000).batch(32, drop_remainder=True).prefetch(-1)\n",
        "\n",
        "residual_test_loader = win_ar_ds(residual_test, size=window_size)\\\n",
        "    .batch(32).prefetch(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OghrwmBoeY8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "history = model_ma.fit(\n",
        "    residual_train_loader,\n",
        "    epochs=400,\n",
        "    verbose=2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='loss'),\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=20,\n",
        "            verbose=2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5FBRYJnoeY8"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k3SlgvRoeY8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model_ma.evaluate(residual_test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0RqFjrHoeY8"
      },
      "outputs": [],
      "source": [
        "forcast_ar = model_ar.predict(test_loader)[window_size:, 0]  # AR é æ¸¬\n",
        "forcast_ma = model_ma.predict(residual_test_loader)[:, 0]  # MA é æ¸¬\n",
        "forcast = forcast_ar+forcast_ma  # åŠ èµ·ä¾†\n",
        "\n",
        "ground_truth_for_view = series_test[window_size*2:]\n",
        "\n",
        "time_for_view = time_test[window_size*2:]\n",
        "\n",
        "plot_series(time_for_view,\n",
        "            [forcast, ground_truth_for_view],\n",
        "            labels=['prediction', 'ground truth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4XKuQ9woeY8"
      },
      "outputs": [],
      "source": [
        "# èˆ‡ç´”ç²¹AR æ¨¡å‹ç›¸æ¯” å¯ä»¥å¾—åˆ°è¼ƒå¥½ä¸€é»é»çš„çµæœ\n",
        "R2(forcast, ground_truth_for_view)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXHudvUKoeY8"
      },
      "source": [
        "ARMAèˆ‡ARIMAæ¨¡å‹åªå·®differencingè€Œå·²ï¼Œå¯ä»¥ä½¿ç”¨ä¸€äº›ç¾æˆçš„å¥—ä»¶å®Œæˆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVW90grHoeY9"
      },
      "source": [
        "## Call Function from Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daRPMwhooeY9"
      },
      "source": [
        "statsmodelsæœ‰æä¾›ARIMAçš„modelï¼Œå°trainingçš„æ™‚é–“é»è³‡æ–™é€²è¡Œæ“¬åˆï¼Œè¨“ç·´å‡ºdiffereced dataçš„ARåŠMAæ¨¡å‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azQAReFsoeY9"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrsJWZhMoeY9"
      },
      "outputs": [],
      "source": [
        "# çµ„æˆARIMAæ¨¡å‹\n",
        "# Args:\n",
        "#  endog (array of float) - æ™‚é–“åºåˆ—\n",
        "#  order (tuple of (int, int, int) ) - ARIMA order, åŒ…å«p,d,q\n",
        "#    p - AR modelçš„coefficientæ•¸é‡\n",
        "#    d - differencingæ¬¡æ•¸\n",
        "#    q - æ“¬åˆresidual termçš„coefficientæ•¸é‡\n",
        "# Returns:\n",
        "#  ARIMAæ¨¡å‹ç‰©ä»¶ (statsmodels.tsa.arima_model)\n",
        "\n",
        "# endog: Input data\n",
        "arima = ARIMA(endog=series_train, order=(7, 1, 7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb-9YHFnoeY9"
      },
      "source": [
        "ç”¨p, d, q åƒæ•¸çµ„å’Œï¼Œé™¤ARIMA modelå¤–ä¹Ÿå¯ä»¥çµ„æˆAR Modelå’ŒARMA model:\n",
        "- AR: (p,0,0) æ²’æœ‰residualä¹Ÿæ²’æœ‰differencing\n",
        "- ARMA: (p,0,q) æœ‰residualæ²’æœ‰differencing\n",
        "- ARIMA: (p,d,q) æœ‰residualä¹Ÿæœ‰differencing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AwOyE5hoeY9"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Q8pcXR7oeY9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "mdl = arima.fit()\n",
        "print(mdl.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQk2oRmLoeY9"
      },
      "source": [
        "Summaryå ±å‘Šä¸­å¯å‘ˆç¾å„åƒæ•¸çš„æ•¸å€¼\n",
        "- const: biasé …\n",
        "- ar.L*.D.y:\n",
        "    - coef: AR modelçš„åƒæ•¸å€¼\n",
        "    - z: regression åƒæ•¸çš„ z çµ±è¨ˆå€¼\n",
        "- ma.L*.D.y:\n",
        "    - coef: MA modelçš„åƒæ•¸å€¼\n",
        "    - z: regression åƒæ•¸çš„ z çµ±è¨ˆå€¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIf4VTuNoeY-"
      },
      "outputs": [],
      "source": [
        "forcast = mdl.forecast(len(series_test))[0]\n",
        "\n",
        "plot_series(time_test,\n",
        "            [forcast, series_test],\n",
        "            labels=['prediction', 'ground truth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrStkIQ4oeY-"
      },
      "outputs": [],
      "source": [
        "R2(forcast, series_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsIU-PxKoeY-"
      },
      "source": [
        "### References\n",
        "* statsmodeså®˜ç¶²: https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html\n",
        "* https://medium.com/analytics-vidhya/arima-model-from-scratch-in-python-489e961603ce\n",
        "* https://www.nbshare.io/notebook/136553745/Time-Series-Analysis-Using-ARIMA-From-StatsModels/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}